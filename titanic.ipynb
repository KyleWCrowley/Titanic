{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import libraries\n",
      "import numpy as np\n",
      "import csv\n",
      "#import specific libraries for models\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import the data file\n",
      "csv_file_object = csv.reader(open('train.csv', 'rb')) \n",
      "header = csv_file_object.next()\n",
      "train_data=[]\n",
      "\n",
      "#put data into an array for use\n",
      "for row in csv_file_object:\n",
      "    train_data.append(row[1:])\n",
      "train_data = np.array(train_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert file to usable format\n",
      "# Convert Gender to numerical values\n",
      "# Female = 0, Male = 1\n",
      "train_data[train_data[0::,3] == 'female',3] = 0\n",
      "train_data[train_data[0::,3] == 'male',3] = 1\n",
      "\n",
      "#Fill in the gaps for the missing ages\n",
      "#Make all missing ages median of the age data\n",
      "train_data[train_data[0::,4] == '',4] = np.median(train_data[train_data[0::,4] != '',4].astype(np.float))\n",
      "\n",
      "#Convert Embarkment Point to numerical format\n",
      "#C=0, S=1, Q=2\n",
      "train_data[train_data[0::,10] == 'C',10] = 0\n",
      "train_data[train_data[0::,10] == 'S',10] = 1\n",
      "train_data[train_data[0::,10] == 'Q',10] = 2\n",
      "\n",
      "#Replace missing prices with median of that classes prices\n",
      "for i in xrange(np.size(train_data[0::,0])):\n",
      "    if train_data[i,8] == '':\n",
      "        train_data[i,8] = np.median(train_data[(train_data[0::,8] != '') & (train_data[0::,0] == train_data[i,0]) ,8].astype(np.float))\n",
      "\n",
      "#Make all missing embarkments the most common embarkment location\n",
      "train_data[train_data[0::,10] == '',10] = np.round(np.mean(train_data[train_data[0::,10] != '',10].astype(np.int)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Delete all irrelevent data (i.e names, cabin, and ticket fields)\n",
      "#These being the names, cabin number, and ticket number\n",
      "#Note: Cabin number field may be worth finding a way to use if time permits\n",
      "train_data = np.delete(train_data,[2,7,9],1)\n",
      "\n",
      "#Ensure array is of a uniform data type now that all data is numerical\n",
      "train_data = np.array(train_data, dtype = np.float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read in test data file\n",
      "test_file_object = csv.reader(open('test.csv', 'rb'))\n",
      "header = test_file_object.next()\n",
      "test_data = []\n",
      "ids = []\n",
      "\n",
      "#Put data into and array for use\n",
      "for row in test_file_object:\n",
      "        ids.append(row[0])\n",
      "        test_data.append(row[1:])\n",
      "test_data = np.array(test_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Convert file to usable format\n",
      "\n",
      "# Convert Gender to numerical values\n",
      "# Female = 0, Male = 1\n",
      "test_data[test_data[0::,2] == 'male',2] = 1\n",
      "test_data[test_data[0::,2] == 'female',2] = 0\n",
      "\n",
      "#Convert Embarkment Point to numerical format\n",
      "#C=0, S=1, Q=2\n",
      "test_data[test_data[0::,9] == 'C',9] = 0\n",
      "test_data[test_data[0::,9] == 'S',9] = 1\n",
      "test_data[test_data[0::,9] == 'Q',9] = 2\n",
      "\n",
      "#Fill in the gaps for the missing ages\n",
      "#Make all missing ages median of the age data\n",
      "test_data[test_data[0::,3] == '',3] = np.round(np.median(test_data[test_data[0::,3] != '',3].astype(np.float)))\n",
      "\n",
      "#Make all missing embarkments the most common embarkment location\n",
      "test_data[test_data[0::,9] == '',9] = np.round(np.mean(test_data[test_data[0::,9] != '',9].astype(np.int)))\n",
      "\n",
      "#Replace missing prices with median of that classes prices\n",
      "for i in xrange(np.size(test_data[0::,0])):\n",
      "    if test_data[i,7] == '':\n",
      "        test_data[i,7] = np.median(test_data[(test_data[0::,7] != '') & (test_data[0::,0] == test_data[i,0]) ,7].astype(np.float))\n",
      "\n",
      "#Delete all irrelevent data (i.e names, cabin, and ticket fields)\n",
      "#These being the names, cabin number, and ticket number\n",
      "test_data = np.delete(test_data,[1,6,8],1)\n",
      "\n",
      "#Ensure array is of a uniform data type now that all data is numerical\n",
      "test_data = np.array(test_data, dtype = np.float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now that data is ready, train the model\n",
      "#Create a classifier\n",
      "forest = RandomForestClassifier(n_estimators=100)\n",
      "#Fit it to the training data\n",
      "forest = forest.fit(train_data[0::,1::],train_data[0::,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now use trained model to predict the results of the test file\n",
      "#Run the model on the test data to get a prediction\n",
      "output = forest.predict(test_data)\n",
      "#convert the prediction to integers so Kaggle understands it\n",
      "output = np.array(output,dtype=np.int)\n",
      "\n",
      "#Output prediction to a file\n",
      "with open(\"RandForests.csv\", 'wb') as predictions:\n",
      "    open_file_object = csv.writer(predictions)\n",
      "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
      "    open_file_object.writerows(zip(ids, output))\n",
      "    predictions.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Linear Regression Model\n",
      "#Create classifiers for L1 ad L2 Regression\n",
      "lr1_classifier = LogisticRegression(penalty = 'l1', tol=.0000001,dual=False)\n",
      "lr2_classifier = LogisticRegression()\n",
      "\n",
      "#performs better when fit to only part of the training data\n",
      "#Chose to train on only first 700 entries as this provides the best results by trial and error\n",
      "blah_train_x, blah_train_y = train_data[:700, 1::], train_data[:700, 0]\n",
      "blah_test_x, blah_test_y = train_data[-100:, 1::], train_data[-100:, 0]\n",
      "\n",
      "\n",
      "#Test models (For figuring out optimal training model size and Tolerance weight)\n",
      "#Run L1 model on untrained portion of training data to get a score\n",
      "lr1_classifier.fit(blah_train_x,blah_train_y)\n",
      "print lr1_classifier.score(blah_test_x, blah_test_y)\n",
      "\n",
      "#Run L2 model on untrained portion of training data to get a score\n",
      "lr2_classifier.fit(blah_train_x,blah_train_y)\n",
      "print lr2_classifier.score(blah_test_x, blah_test_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.83\n",
        "0.81\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now use trained model to predict the results of the test file\n",
      "#Run the model on the test data to get a prediction\n",
      "output2 = lr1_classifier.predict(test_data)\n",
      "#convert the prediction to integers so Kaggle understands it\n",
      "output2 = np.array(output2,dtype=np.int)\n",
      "\n",
      "#Run the model on the test data to get a prediction\n",
      "output3 = lr2_classifier.predict(test_data)\n",
      "#convert the prediction to integers so Kaggle understands it\n",
      "output3 = np.array(output3,dtype=np.int)\n",
      "\n",
      "#Output prediction to a file\n",
      "with open(\"L1Predictions.csv\", 'wb') as logreg:\n",
      "    open_file_object = csv.writer(logreg)\n",
      "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
      "    open_file_object.writerows(zip(ids, output2))\n",
      "    logreg.close()\n",
      "\n",
      "#Output prediction to a file\n",
      "with open(\"L2Predictions.csv\", 'wb') as logreg2:\n",
      "    open_file_object = csv.writer(logreg2)\n",
      "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
      "    open_file_object.writerows(zip(ids, output3))\n",
      "    logreg2.close()\n",
      "    \n",
      "#Average the results of all 3 models to get a more accuracte prediction\n",
      "averg = (output3 + output2 + output)/3\n",
      "#Output prediction to a file\n",
      "with open(\"AveragedOuputs.csv\", 'wb') as avg:\n",
      "    open_file_object = csv.writer(avg)\n",
      "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
      "    open_file_object.writerows(zip(ids, averg))\n",
      "    avg.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}